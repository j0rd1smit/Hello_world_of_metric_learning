{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Hello World of Deep Metric Learning: Siamese Contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin, *, eps:float=1e-9):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, output1, output2, target):\n",
    "        positve_loss = target.float() * (output2 - output1).pow(2).sum(1)\n",
    "        negative_loss = (1 + -1 * target).float() * F.relu(self.margin - (output2 - output1).pow(2).sum(1) + self.eps).pow(2)\n",
    "\n",
    "        loss = positve_loss + negative_loss\n",
    "\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_dataset(\n",
    "        *,\n",
    "        train: bool,\n",
    "        exclude_labels = None,\n",
    "):\n",
    "    exclude_labels = exclude_labels if exclude_labels is not None else []\n",
    "    mean, std = 0.1307, 0.3081\n",
    "    transforms = T.Compose([\n",
    "                    T.ToTensor(),\n",
    "                    T.Normalize((mean,), (std,))\n",
    "                ])\n",
    "\n",
    "    dataset = MNIST('../data/MNIST',\n",
    "      train=train,\n",
    "      download=True,\n",
    "      transform=transforms,\n",
    "    )\n",
    "\n",
    "    for label in exclude_labels:\n",
    "        dataset.data = dataset.data[dataset.targets != label]\n",
    "        dataset.targets = dataset.targets[dataset.targets != label]\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseMNIST(Dataset):  \n",
    "    def __init__(self, mnist_dataset):  \n",
    "        self.mnist_dataset = mnist_dataset  \n",
    "  \n",
    "        self.train = self.mnist_dataset.train  \n",
    "        self.transform = self.mnist_dataset.transform  \n",
    "  \n",
    "        self.labels = self.mnist_dataset.targets  \n",
    "        self.data = self.mnist_dataset.data  \n",
    "        self.labels_set = set(self.labels.numpy())  \n",
    "        self.label_to_indices = {label: np.where(self.labels.numpy() == label)[0] for label in self.labels_set}  \n",
    "  \n",
    "        if not self.train:  \n",
    "\t        # During validation, always pick the same tuple.\n",
    "            np.random.seed(42)  \n",
    "            self.val_data = [self._draw(i) for i, _ in enumerate(self.data)]  \n",
    "  \n",
    "  \n",
    "    def __getitem__(self, index):  \n",
    "        if self.train:\n",
    "\t         # Randomly pick during training  \n",
    "            image1, image2, target, label1 = self._draw(index)  \n",
    "        else:  \n",
    "\t        # During validation always pick the same tuple.\n",
    "            image1, image2, target, label1 = self.val_data[index]  \n",
    "  \n",
    "        if self.transform is not None:  \n",
    "            image1 = self.transform(image1)  \n",
    "            image2 = self.transform(image2)  \n",
    "  \n",
    "        return (image1, image2), (target, label1)  \n",
    "  \n",
    "    def _draw(self, index):  \n",
    "        image1 = self.data[index]  \n",
    "        label1 = self.labels[index]  \n",
    "  \n",
    "        target = np.random.choice([0, 1])  \n",
    "        if target == 1:  \n",
    "            # Pick a random image with the same label as image1.\n",
    "            siamese_index = np.random.choice(self.label_to_indices[int(label1)])  \n",
    "        else:  \n",
    "\t        # Pick a random label that is not the same as image1.\n",
    "            siamese_label = np.random.choice(list(self.labels_set - {label1}))  \n",
    "            # Pick a random image with the randomly chosen label.\n",
    "            siamese_index = np.random.choice(self.label_to_indices[siamese_label])  \n",
    "  \n",
    "        image2 = self.data[siamese_index]  \n",
    "\t\t# Load the images\n",
    "        image1 = Image.fromarray(image1.numpy(), mode='L')  \n",
    "        image2 = Image.fromarray(image2.numpy(), mode='L')  \n",
    "  \n",
    "        return image1, image2, target, label1  \n",
    "  \n",
    "    def __len__(self):  \n",
    "        return len(self.mnist_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_accuracy(embeddings, labels):\n",
    "    embeddings = embeddings.detach().cpu()\n",
    "    labels = labels.detach().cpu()\n",
    "\n",
    "    return KNeighborsClassifier().fit(embeddings, labels).score(embeddings, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_plot_image(embeddings, labels):\n",
    "    colours = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\", \"tab:pink\", \"tab:gray\", \"tab:olive\", \"tab:cyan\"]\n",
    "\n",
    "    embeddings = embeddings.detach().cpu()\n",
    "    labels = labels.detach().cpu()\n",
    "    for label in torch.unique(labels):\n",
    "        color = colours[int(label) % len(colours)]\n",
    "        idx_slice = labels == label\n",
    "        plt.scatter(embeddings[idx_slice, 0], embeddings[idx_slice, 1], label=str(int(label)), c=color)\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid()\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='jpg')\n",
    "    buf.seek(0)\n",
    "    image = cv2.imdecode(np.frombuffer(buf.getvalue(), np.uint8), -1)\n",
    "    image = image.transpose(2, 0, 1)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBackbone, self).__init__()\n",
    "        self.convnet = nn.Sequential(nn.Conv2d(1, 32, 5), nn.PReLU(),\n",
    "                                     nn.MaxPool2d(2, stride=2),\n",
    "                                     nn.Conv2d(32, 64, 5), nn.PReLU(),\n",
    "                                     nn.MaxPool2d(2, stride=2))\n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(64 * 4 * 4, 256),\n",
    "                                nn.PReLU(),\n",
    "                                nn.Linear(256, 256),\n",
    "                                nn.PReLU(),\n",
    "                                nn.Linear(256, 2)\n",
    "                                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.convnet(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiamaseNet(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        batch_size,\n",
    "        n_workers\n",
    "    ):\n",
    "        super(SiamaseNet, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.n_workers = n_workers\n",
    "        \n",
    "        \n",
    "        self.backbone = ConvBackbone()\n",
    "        self.loss_func = ContrastiveLoss(margin=1.0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (input1, input2), (targets, labels) = batch\n",
    "        embedding1 = self(input1)\n",
    "        embedding2 = self(input2)\n",
    "        loss = self.loss_func(embedding1, embedding2, targets)\n",
    "\n",
    "        log = {\"train_loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": log, \"embeddings\": embedding1, \"labels\": labels}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        embeddings = torch.cat([x['embeddings'] for x in outputs])\n",
    "        labels = torch.cat([x['labels'] for x in outputs])\n",
    "\n",
    "        plot = create_embeddings_plot_image(embeddings, labels)\n",
    "        self.logger.experiment.add_image('embedding_space/train', plot, self.current_epoch)\n",
    "\n",
    "        accuracy = knn_accuracy(embeddings, labels)\n",
    "\n",
    "        log = {'avg_train_loss': loss, \"knn_accuracy/train\": accuracy}\n",
    "        return {'log': log, 'train_loss': loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self._create_dataloader(\n",
    "            SiameseMNIST(get_mnist_dataset(\n",
    "                train=True,\n",
    "            )),\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "    def _create_dataloader(self, dataset, shuffle):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=self.n_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        (input1, input2), (targets, labels) = batch\n",
    "        embedding1 = self(input1)\n",
    "        embedding2 = self(input2)\n",
    "        loss = self.loss_func(embedding1, embedding2, labels)\n",
    "\n",
    "        return {\"val_loss\": loss, \"embeddings\": embedding1, \"labels\": labels}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        val_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        embeddings = torch.cat([x['embeddings'] for x in outputs])\n",
    "        labels = torch.cat([x['labels'] for x in outputs])\n",
    "\n",
    "        plot = create_embeddings_plot_image(embeddings, labels)\n",
    "        self.logger.experiment.add_image('embedding_space/val', plot, self.current_epoch)\n",
    "\n",
    "        accuracy = knn_accuracy(embeddings, labels)\n",
    "\n",
    "\n",
    "        log = {'avg_val_loss': val_loss, \"knn_accuracy/val\": accuracy}\n",
    "        return {'log': log, 'val_loss': val_loss}\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self._create_dataloader(\n",
    "            SiameseMNIST(get_mnist_dataset(train=False)),\n",
    "            shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type            | Params\n",
      "----------------------------------------------\n",
      "0 | backbone  | ConvBackbone    | 380 K \n",
      "1 | loss_func | ContrastiveLoss | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e47b15b40834bcd84ceb976e17b0644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 512\n",
    "n_workers = 8\n",
    "epochs = 20\n",
    "gpus = 1\n",
    "\n",
    "model = SiamaseNet(batch_size=batch_size, n_workers=n_workers)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=gpus,\n",
    "    fast_dev_run=True,\n",
    "    max_epochs=epochs,\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
